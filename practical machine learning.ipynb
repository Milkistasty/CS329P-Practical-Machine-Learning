{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.headless = True\n",
    "chrome = webdriver.Chrome(\n",
    "    options = chrome_options\n",
    ")\n",
    "\n",
    "page = chrome.get(\"https://www.zillow.com/stanford-ca/sold/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.zillow.com/homedetails/19506780_zpid/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "links = [a['href'] for a in soup.find_all('a', class_='list-card-link')]\n",
    "ids = [l.split('/')[-2].split('-')[0] for l in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the 'ds-home-details-chip' div.\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "# Find the 'ds-home-details-chip' div\n",
    "details_div = soup.find('div', 'ds-home-details-chip')\n",
    "\n",
    "if details_div:\n",
    "    p_tag = details_div.find('p')\n",
    "    if p_tag:\n",
    "        sold_items = [a.text for a in p_tag.find_all('span')]\n",
    "        \n",
    "        # Iterate through the extracted items and search for desired details\n",
    "        for item in sold_items:\n",
    "            if 'Sold:' in item:\n",
    "                result['Sold Price'] = item.split(' ')[1]\n",
    "            if 'Sold on' in item:\n",
    "                result['Sold On'] = item.split(' ')[-1]\n",
    "else:\n",
    "    print(\"Could not find the 'ds-home-details-chip' div.\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "# Fetching the content of the Zillow page\n",
    "url = 'https://www.zillow.com/homedetails/2626-Iron-St-Bellingham-WA-98225/23624938_zpid/'  # Replace with the actual URL\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "# Extracting the image IDs using regex\n",
    "p = r'https:\\\\/\\\\/photos.zillowstatic.com\\\\/fp\\\\/(\\d\\w\\-\\_]+).jpg'\n",
    "ids = [a.split('-')[0] for a in re.findall(p, html)]\n",
    "\n",
    "# Constructing the image URLs\n",
    "urls = [f'https://photos.zillowstatic.com/fp/{id}-uncropped_scaled_within_1536_1152.jpg' for id in ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "    <meta name=\"description\" content=\"px-captcha\">\n",
      "    <title>Access to this page has been denied</title>\n",
      "    \n",
      "</head>\n",
      "<body>\n",
      "<script>\n",
      "    /* PerimeterX assignments */\n",
      "    window._pxVid = '';\n",
      "    window._pxUuid = 'faf9548e-5c20-11ee-a3b0-4695041729ec';\n",
      "    window._pxAppId = 'PXHYx10rg3';\n",
      "    window._pxMobile = false;\n",
      "    window._pxHostUrl = '/HYx10rg3/xhr';\n",
      "    window._pxCustomLogo = 'https://www.zillowstatic.com/s3/pfs/static/z-logo-default.svg';\n",
      "    window._pxJsClientSrc = '/HYx10rg3/init.js';\n",
      "    window._pxFirstPartyEnabled = true;\n",
      "    var pxCaptchaSrc = '/HYx10rg3/captcha/captcha.js?a=c&u=faf9548e-5c20-11ee-a3b0-4695041729ec&v=&m=0';\n",
      "\n",
      "    var script = document.createElement('script');\n",
      "    script.src = pxCaptchaSrc;\n",
      "    script.onerror = function () {\n",
      "        script = document.createElement('script');\n",
      "        script.src = 'https://captcha.px-cloud.net/PXHYx10rg3/captcha.js?a=c&amp;u=faf9548e-5c20-11ee-a3b0-4695041729ec&amp;v=&amp;m=0';\n",
      "        script.onerror = window._pxOnError;\n",
      "        document.head.appendChild(script);\n",
      "    };\n",
      "    window._pxOnError = function () {\n",
      "        var style = document.createElement('style');\n",
      "        style.innerText = '@import url(https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap);body{background-color:#fafbfc}.px-captcha-error-container{position:fixed;height:340px;background-color:#fff;font-family:Roboto,sans-serif}.px-captcha-error-header{color:#f0f1f2;font-size:29px;margin:67px 0 33px;font-weight:500;line-height:.83;text-align:center}.px-captcha-error-message{color:#f0f1f2;font-size:18px;margin:0 0 29px;line-height:1.33;text-align:center}.px-captcha-error-button{text-align:center;line-height:48px;width:253px;margin:auto;border-radius:50px;border:solid 1px #f0f1f2;font-size:20px;color:#f0f1f2}.px-captcha-error-wrapper{margin:18px 0 0}div.px-captcha-error{margin:auto;text-align:center;width:400px;height:30px;font-size:12px;background-color:#fcf0f2;color:#ce0e2d}img.px-captcha-error{margin:6px 8px -2px 0}.px-captcha-error-refid{border-top:solid 1px #f0eeee;height:27px;margin:13px 0 0;border-radius:0 0 3px 3px;background-color:#fafbfc;font-size:10px;line-height:2.5;text-align:center;color:#b1b5b8}@media (min-width:620px){.px-captcha-error-container{width:530px;top:50%;left:50%;margin-top:-170px;margin-left:-265px;border-radius:3px;box-shadow:0 2px 9px -1px rgba(0,0,0,.13)}}@media (min-width:481px) and (max-width:620px){.px-captcha-error-container{width:85%;top:50%;left:50%;margin-top:-170px;margin-left:-42.5%;border-radius:3px;box-shadow:0 2px 9px -1px rgba(0,0,0,.13)}}@media (max-width:480px){body{background-color:#fff}.px-captcha-error-header{color:#f0f1f2;font-size:29px;margin:55px 0 33px}.px-captcha-error-container{width:530px;top:50%;left:50%;margin-top:-170px;margin-left:-265px}.px-captcha-error-refid{position:fixed;width:100%;left:0;bottom:0;border-radius:0;font-size:14px;line-height:2}}@media (max-width:390px){div.px-captcha-error{font-size:10px}.px-captcha-error-refid{font-size:11px;line-height:2.5}}';\n",
      "        document.head.appendChild(style);\n",
      "        var div = document.createElement('div');\n",
      "        div.className = 'px-captcha-error-container';\n",
      "        div.innerHTML = '<div class=\"px-captcha-error-header\">Before we continue...</div><div class=\"px-captcha-error-message\">Press & Hold to confirm you are<br>a human (and not a bot).</div><div class=\"px-captcha-error-button\">Press & Hold</div><div class=\"px-captcha-error-wrapper\"><div class=\"px-captcha-error\"><img class=\"px-captcha-error\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAQCAMAAADDGrRQAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAABFUExURUdwTNYELOEGONQILd0AONwALtwEL+AAL9MFLfkJSNQGLdMJLdQJLdQGLdQKLtYFLNcELdUGLdcBL9gFL88OLdUFLNEOLglBhT4AAAAXdFJOUwC8CqgNIRgRoAS1dWWuR4RTjzgryZpYblfkcAAAAI9JREFUGNNdj+sWhCAIhAdvqGVa1r7/oy6RZ7eaH3D4ZACBIed9wlOOMtUnSrEmZ6cHa9YAIfsbCkWrdpi/c50Bk2CO9mNLdMAu03wJA3HpEnfpxbyOg6ruyx8JJi6KNstnslp1dbPd9GnqmuYq7mmcv1zjnbQw8cV0xzkqo+fX1zkjUOO7wnrInUTxJiruC3vtBNRoQQn2AAAAAElFTkSuQmCC\">Please check your internet connection' + (window._pxMobile ? '' : ' or disable your ad-blocker') + '.</div></div><div class=\"px-captcha-error-refid\">Reference ID ' + window._pxUuid + '</div>';\n",
      "        document.body.appendChild(div);\n",
      "        if (window._pxMobile) {\n",
      "            setTimeout(function() {\n",
      "                location.href = '/px/captcha_close?status=-1';\n",
      "            }, 5000);\n",
      "        }\n",
      "    };\n",
      "    document.head.appendChild(script);\n",
      "</script>\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules to check if YouTube comments are spam or ham\n",
    "def check_out(x):\n",
    "    return SPAM if \"check out\" in x.lower() else ABSTAIN\n",
    "def sentiment(x):\n",
    "    return HAM if sentiment_polarity(x) > 0.9 else ABSTAIN\n",
    "def short_comment(x):\n",
    "    return HAM if len(x.split()) < 5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ways to get data\n",
    "### scraping\n",
    "### cloud-sourcing\n",
    "### active learning: chooses an example whose prediction is most uncertain, and give it to the human moderator to label\n",
    "### self-training: iteratively train models to label unlabaled data\n",
    "### data programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - Exploratory Data Aanalsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alienware\\AppData\\Local\\Temp\\ipykernel_29500\\372091493.py:6: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  display.set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('house_sale.zip')\n",
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_sum = data.isnull().sum()\n",
    "data.columns[null_sum < len(data) * 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=data.columns[null_sum > len(data) * 0.3], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency = ['Sold Price', 'Listed Price', 'Tax assessed value', 'Annual tax amount']\n",
    "for c in currency:\n",
    "    data[c] = data[c].replace(\n",
    "        r'[$,-]', '', regex=True  # dollar symbol and - normally means no data, change to empty\n",
    "    ).replace(  \n",
    "        r'^\\s*$', np.nan, regex=True  # empty string\n",
    "    ).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ['Total interior livable area', 'Lot size']\n",
    "for c in areas:\n",
    "    acres = data[c].str.contains('Acres') == True\n",
    "    col = data[c].replace(  \n",
    "        r'\\b sqrt\\b|\\b Acres\\b|\\b,\\b', '', regex=True\n",
    "    ).astype(float)  \n",
    "    col[acres] *= 43560\n",
    "    data[c] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal = (data[areas[1]] < 10) | (data[areas[1]] > 1e4)\n",
    "data = data[~abnormal]\n",
    "sum(abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(np.log10(data['Sold Price']))\n",
    "ax.set_xlim([3, 8])\n",
    "ax.set_xticks(range(3, 9))\n",
    "ax.set_xticklabels(['%.0e'%a for a in 10**ax.get_xticks()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'].value_counts()[0:20] # get the unique value and corresponding count within one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data['Type'].isin(['SingleFamily', 'Condo', 'MultiFamily', 'Townhouse'])\n",
    "sns.displot(pd.DataFrame({'Sold Price': np.log10(data[types]['Sold Price']),\n",
    "                          'Type': data[types]['Type']}),\n",
    "                          x='Sold Price', hue='Type', kind='kde' # density\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Price per living sqft'] = data['Sold Price'] / data['Total interior livable area']\n",
    "ax = sns.boxplot(x='Type', y='Price per living sqft', data=data[types], filtersize=0)\n",
    "ax.set_ylim([0, 2000])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(6,6))\n",
    "columns = ['Sold Price', 'Listed Price', 'Annual tax amount', 'Price per living sqft', 'Elementary School Score', 'High School Score']\n",
    "sns.heatmap(data[columns].corr(), annot=True, cmap='RdYlGn', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'].value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tabular data\n",
    "## Normalization for read value columns\n",
    "### 1. Min-max normalization: linearly map to a new min a and max b\n",
    "### xi` = (xi - min(x)) / (max(x) - min(x)) * (b - a) + a\n",
    "### 2. Z-score normalization: 0 mean, 1 std\n",
    "### xi` = (xi - mean(x)) / std(x)\n",
    "### 3. Decimal scaling:\n",
    "### xi` = xi / (10 ** j)\n",
    "### 4. Log scaling:\n",
    "### xi` = log(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Transformations\n",
    "### Downsampling and cropping\n",
    "### reduce image sizes: save storage and for fast loading\n",
    "### jpeg will affect the image quality (80% acc)\n",
    "### image whitening: make input less redundant, model converges faster\n",
    "\n",
    "## Average video length\n",
    "### movies - 2h, YouTube videos - 11 min, TikTok short videos - 15 sec\n",
    "## Preprocessing to balance storage, quality and loading speed\n",
    "## we often use short video clips (< 10 sec>): each clip contains a single event(i.e. human action)\n",
    "## Decode a playable video, sample a sequence of frames\n",
    "### best for loading, but 10x more space\n",
    "### computation may be cheaper than storage (i.e. use GPU to decode)\n",
    "### can apply other image transformation to the frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Transformation\n",
    "## stemming and lemmatization: a word -> a common base form\n",
    "### i.e. am, are, is -> be\n",
    "## Tokenization: text -> a list of tokens (smallest unit to ML algo)\n",
    "### by word: text.split(' ')\n",
    "### by char: text.split('')\n",
    "### by subwords: unigram, wordpiece, i.e. \"a new gpu!\" -> \"a\", \"new\", \"gp\", \"##u\", \"!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering\n",
    "## tabular data features\n",
    "## int/float: directly use or bin to n unique int values\n",
    "## categorical data: one-hot encoding, map rare categories into \"unknown\"\n",
    "## data-time: a feature list such as [year, month, day, day_of_year, week_of_year, day_of_week]\n",
    "## feature combination: cartesian product of two feature\n",
    "### [cat, dog] * [male, female] -> \n",
    "### [(cat, male), (cat, female), (dog, male), (dog, female)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text features\n",
    "## represent text as token features\n",
    "## bag of words (BoW) model\n",
    "### i.e. dog and cat and dinosaur:  fish, cat, and, dog, unknown -> [0, 1, 2, 1, 1]\n",
    "### limitations: needs careful vocabulary design, missing context\n",
    "## word embeddings (e.g. Word2vec):\n",
    "### vectorizing words such that similar words are placed close together\n",
    "### trained by predicting target word from context words\n",
    "## pre-trained language models(e.g. BERT, GPT-3)\n",
    "### giant transformer models\n",
    "### trained with large amount of unannotated data\n",
    "### fine-tuning for downstream tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image/video features\n",
    "### traditionally extract images by hand-craft features such as SIFT\n",
    "### now commonly use pre-trained deep neural networks\n",
    "### resnet: trained with imagenet (image classification)\n",
    "### I3D: trained with Kinetics (action classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## challenges\n",
    "### trade-off between label quality vs data volume\n",
    "### data quality: \n",
    "### diversity: all relevant aspects are represented\n",
    "### unbiased: no biased on a particular side\n",
    "### faireness: non discriminating treatment of data and people\n",
    "## large-scale data management: storage, process, version, security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decision trees\n",
    "### pros: explainable, can handle both numerical and categorical features\n",
    "### cons: very non-robust (ensemble to help), complex trees cause overfitting (prune trees), not easy to be parallelized in computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest\n",
    "### train multiple decision trees to improve robustness\n",
    "### each tree is trained independently\n",
    "### majority voting for classfication, average for regression\n",
    "## where is the randomness from?\n",
    "### bagging: randomly sample training examples with replacement i.e. [1,2,3,4,5] -> [1,2,2,3,4]\n",
    "### randomly select a subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Decision Trees\n",
    "### train multiple trees sequentially on residuals of error (loss function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "### softmax regression to solve classification problem\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0_exp = torch.exp(0)\n",
    "partition = 0_exp.sum(1, keepdim=True)\n",
    "Y = 0_exp / partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch Stochastic Gradient Descent (SGD)\n",
    "### w model param, b batch size, nt learning rate at time t\n",
    "### randomly initialized w1\n",
    "### reprat t = 1,2,... until converge\n",
    "#### randomly samples It <- 1,2,...,n with |I| = b\n",
    "#### update Wt+1 = Wt - nt * gradient(wt)\n",
    "### Pros: solve all objectives in this course except for trees\n",
    "### Cons: sensitive to hyper-parameters b and nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### train a linear regression model with min-batch SGD\n",
    "## Hyperparameters \n",
    "### batch_size, learning_rate, num_epochs\n",
    "\n",
    "`features ` shape is (n, p), 'labels' shape is (p, 1)\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)  # read examples at random\n",
    "    for i in range(0, number_examples, batch_size):\n",
    "        batch_indices = torch.tensor(\n",
    "            indices[i:min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n",
    "w = torch.normal(0, 0.01, size=(p, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels)\n",
    "        y_hat = X @ w + b\n",
    "        loss = ((y_hat - y)**2 / 2).mean\n",
    "        loss.backward()  # get the gredient of loss\n",
    "        for param in [w, b]:  # update the w and b\n",
    "            param -= learning_rate * param.grad \n",
    "            param.grad.zero()  # reset the gradient to zero, so that we can compute the gradient again in the next epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "## NN usually requires more data and more computation\n",
    "## NN architectures to model data structures\n",
    "### Multilayer perception (MLP), Convolutional Neural Networks, Recurrent Neural Networks, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "## A dense (fully connected, or linear) layer has parameters W <- R(m*n), b <- R(m), it computes output y = Wx + b <- R(m)\n",
    "### Linear Regression: dense layer with 1 output\n",
    "### Softmax regression: dense layer with m outputs + softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation is a elemental-wise non-linear function\n",
    "### sigmoid(x) = 1 / (1 + exp(-x))\n",
    "### ReLU(x) = max(x, 0)\n",
    "### it leads to non-linear models\n",
    "\n",
    "## Stack multiple hidden layers\n",
    "### (dense + activation) to get deeper models\n",
    "\n",
    "## Hyper-parameters\n",
    "### # hidden layers\n",
    "### # outputs for each hidder layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code\n",
    "\n",
    "MLP with 1 hidder layer\n",
    "Hyperparameter: num_hiddens\n",
    "\n",
    "def relu(x):\n",
    "    return torch.max(X, 0)   # for each element, get the max of (element, 0)\n",
    "\n",
    "W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens) * 0.01)\n",
    "b1 = nn.Parameter(torch.zeros(num_hiddens))\n",
    "W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(num_outputs))\n",
    "\n",
    "H = relu(X @ W1 + b1)  # hidden layer output\n",
    "Y = H @ W2 + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution layer\n",
    "## Learn ImageNet (300*300 images with 1K classes) by a MLP with a single hidden layer with 10K outputs\n",
    "### it leads to 1 billion learnable parameters, that's too big!\n",
    "### fully connected: an output is a weighted sum over all intputs\n",
    "## recognize objects in images\n",
    "### translation invariance: similar output no matter where the object is\n",
    "### locality: pixels are more related to near neighbors\n",
    "## build the prior knowledge into the model structure\n",
    "### achieve same model capacity with less # params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locality: an output is computed from k*k input windows\n",
    "### Translation invariant: outputs use the same k*k weights(kernel)\n",
    "### number of model params of a conv layer does not depend on input/output sizes\n",
    "### A kernel may learn to identify a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### Convolution with single input and output channels\n",
    "\n",
    "### both input 'X' and weight 'K' are matrices\n",
    "h, w = K.shape\n",
    "Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        Y[i, j] = (X[i:i + h, j:j + w] * k).sum()\n",
    "        # X[i:i+h] here it is called cross-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "### Convolution is sensitive to location\n",
    "### A pixel shift in the input results in a pixel shift in output\n",
    "### A pooling layer computes mean/max in k*k windows\n",
    "\n",
    "# h, w: pooling window height and weight\n",
    "# mode: max or avg\n",
    "Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "for i in range(Y.shape[0]):\n",
    "    for j in range(Y.shape[1]):\n",
    "        if mode == 'max':\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * k).max()\n",
    "        if mode == 'avg':\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * k).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNN)\n",
    "## A neural network uses stack of convolution layers to extract features\n",
    "### Activation is applied after each convolution layer, to add some non-linear transformation\n",
    "### Using pooling to reduce location sensitivity, adaptable to tiny position change or noises\n",
    "## Modern CNNs are deep neural network with various hyper-parameters and layer connections (AlexNet, VGG, Inceptions, ResNet, MobileNet) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. Conv -> Pooling -> Conv -> Pooling -> Dense -> Outputs\n",
    "\n",
    "lenet = nn.sequential(\n",
    "nn.Conv2d(...),\n",
    "nn.Sigmoid(),\n",
    "nn.AvgPool2d(...),\n",
    "nn.Conv2d(),\n",
    "nn.Sigmoid(),\n",
    "nn.AvgPool2d(...),\n",
    "nn.Flatten(),\n",
    "nn.Linear(...),\n",
    "nn.Sigmoid(),\n",
    "nn.Linear(...),\n",
    "nn.Sigmoid(),\n",
    "nn.Linear(...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Layer -> Recurrent networks\n",
    "\n",
    "## Language model: predict the next word\n",
    "### hello -> world;   hello world -> !\n",
    "## Use MLP naively doesn't handle sequence info well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN and Gated RNN\n",
    "## Simple RNN: h(t) = sigma * (W(hh) * h(t-1) + W(hx) * x(t) + b(h))\n",
    "## Gated RNN (LSTM, GRU): finer control of information flow\n",
    "### forget input: suppress X(t) when computing h(t)\n",
    "### forget past: suppress h(t-1) when computing h(t)\n",
    "### when should we forget input or past? we will assign a different weights to computes it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "## Implement Simple RNN\n",
    " \n",
    "W_xh = nn.Parameter(torch.randn(num_inputs, num_hiddens) * 0.01) \n",
    "W_hh = nn.Parameter(torch.randn(num_inputs, num_hiddens) * 0.01)\n",
    "b_h = nn.Parameter(torch.zeros(num_hiddens))\n",
    "\n",
    "H = torch.zeros(num_hiddens)  # at the time zero, the history information is null\n",
    "outputs = []\n",
    "\n",
    "for X in inputs:  # 'inputs' shape : (num_steps, batch_size, num_inputs)\n",
    "    H = torch.tanh(X @ W_xh + H @ W_hh + b_h)\n",
    "    outputs.append(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-RNN and Deep RNN\n",
    "we can look at a sentence from 2 directions, from right to left, from left to right\n",
    "\n",
    "# Deep RNN\n",
    "t -> RNN -> RNN -> RNN -> outputs\n",
    "each RNN layer can be bi-directional or LSTM etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular -> Trees/Linear/MLP\n",
    "# Text/Speech -> RNNS/Transformers\n",
    "# Images/Audio/Video -> Transformers/CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## MLP: stack dense layers with non-linear activations\n",
    "## CNN: stack convolution activation and pooling layers to efficient extract spatial information\n",
    "## RNN: stack recurrent layers to pass temporal information through hidden state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Bias & Variance\n",
    "\n",
    "## Model generalization error: bias, variance and intrinsic error\n",
    "\n",
    "## Reduce Bias: A more complex model, i.e. increase # layers, # hidden units in neural network\n",
    "### Boosting, Stacking\n",
    "## Reduce Variance: A simpler model, Regularization, i.e. L1,L2 regularizations\n",
    "### Bagging, Stacking\n",
    "## Reduce sigma^2: Improve data\n",
    "\n",
    "## Ensemble Learning: use multiple models to improve predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging - Bootstrap Aggrgrating\n",
    "\n",
    "## Bagging trains n base learners in parallel\n",
    "## Make decisions by averaging learners' outputs (regression) or majority voting (classification)\n",
    "## Each learner is trained on data by bootstrap sampling\n",
    "### Assume m training examples, then randomly sampling m examples with replacement (repeative picking)\n",
    "### Around 1 - 1/e = 63% examples will be sampled, the rest of bag can be used for validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code: \n",
    "\n",
    "class Bagging:\n",
    "    def __init__(self, base_learner, n_learners)：\n",
    "        self.learners = [clone(base_learner) for _ in range(n_learners)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for learner in self.learners:\n",
    "            examples = np.random.choice(\n",
    "                np.arange(len(X)), int(len(X)), replace = True\n",
    "            )\n",
    "            learner.fit(X.iloc[examples, :], y.iloc[examples])\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = [learner.predict(X) for learner in self.learners]\n",
    "        return np.array(preds).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "## Use decision tree as the base learner\n",
    "## Often randomly select a subset of features for each learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unstable Learners\n",
    "## Bagging reduces variance, especially for unstable learners\n",
    "## Bagging reduces variance more, when base learners are more unstable\n",
    "## Decision tree is unstable, linear regression is stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "## Boosting combines weak learners into a strong one\n",
    "### Primarily to reduce bias\n",
    "## Learn n weak learners sequentially, at step i:\n",
    "### Train a weak learner h(i), evaluate its errors epsilon(t)\n",
    "### re-sample data according to epsilon(t) to focus on wrongly predicted examples\n",
    "## Notable examples include AdaBoost, gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "## Denote by H(t)(x) the model at time t, with H(1)(x) = 0\n",
    "## At step t = 1,2,...\n",
    "### Train a new model h(t) on residuals: {(x(i), y(i) - H(t)(x(i)))}, i = 1,2,...\n",
    "### H(t+1)(x) = H(t)(x) + aita * H(t)(x)\n",
    "#### The learning rate aita regularizes the model by shrinkage\n",
    "## The residuals equal to -dL/dH if using MSE as the loss\n",
    "### Other boosting algo (i.e. AdaBoost) can also be gradient descent in the function space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code:\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, base_learner, n_learners, learning_rate)：\n",
    "        self.learners = [clone(base_learner) for _ in range(n_learners)]\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        residual = y.copy()\n",
    "        for learner in self.learners:\n",
    "            learner.fit(X, residual)\n",
    "            residual -= self.lr * learner.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = [learner.predict(X) for learner in self.learners]\n",
    "        return np.array(preds).sum(axis=0) * self.lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Decision Trees (GBDT)\n",
    "## Use decision tree as the week learner\n",
    "### Regularize by a small max_depth and randomly sampling features\n",
    "## Sequentially constructing trees runs slow\n",
    "### Popular libs use accelerated algo, i.e. XGBoost, lightGBM, these 2 algos only run faster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## Boosting combines weak learners into a strong one to reduce bias\n",
    "## Gradient boosting learns weak learners by fitting the residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking \n",
    "## Combine multiple base learners to reduce variance\n",
    "### Base learners can be different model types \n",
    "### Linearly combine base learners outputs by learned parameters\n",
    "## Widely used in competitions\n",
    "## In comparison, bagging\n",
    "### uses same type models, uses bootstrap to get diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Stacking \n",
    "## Stacking base learners in multiple levels to reduce bias\n",
    "### can use a different set of base learners at each level\n",
    "## Upper levels (i.e. L2) are trained on the outputs of the below level (i.e. L1)\n",
    "### Concatenating original inputs helps\n",
    "## But multi-layer stacking very easy leads to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting in Multi-layer Stacking\n",
    "## Train learners from different levels on different data to alleviate overfitting \n",
    "### Split training data into A and B, train L1 learners on A, predict on B to generate inputs to L2 learners\n",
    "## Repeated k-fold bagging:\n",
    "### Train k models as in k-fold cross validation\n",
    "### Combine predictions of each model on out-of-fold data\n",
    "### Repeat step 1,2 by n times, average the n predictions of each example for the next level training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Hyperparameter Tuning\n",
    "## Start with a good baseline, e.g. default settings in high-quality toolkits, values reported in papers\n",
    "## Tune a value, retrain the model to see the changes\n",
    "## Repeat multiple times to gain insights about\n",
    "### Which hyperparameters are important\n",
    "### How sensitive the model to hyperparameters\n",
    "### What are the good ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO algorithms\n",
    "## Hyperparameter Optimization\n",
    "### Black box -> Grid Search, Random Search, Bayesian Optimization, Simulated Annealing, Genetic Algorithms\n",
    "### Multi-fidelity Optimization -> Modeling Learning Curve, Bandit Based -> Successive Having, Hyper-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "for config in search_space:\n",
    "    train_and_eval(config)\n",
    "return best_result\n",
    "\n",
    "### All combinations are evaluated\n",
    "### Guarantees the best result\n",
    "### Curse of dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search (the most common way)\n",
    "\n",
    "for _ in range(n):\n",
    "    config = random_select(search_space)\n",
    "    train_and_eval(config)\n",
    "return best_result\n",
    "\n",
    "### Random combinations are tried\n",
    "### More efficient than grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization (BO)\n",
    "### BO: Iteratively learn a mapping from HP to objective function. Based on previous trials. Select the next trial based on the current estimation.\n",
    "### Surrogate model: Estimate how the objective function depends on HP. Probabilistic regression models: Random Forest, Gaussian Process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition function\n",
    "### Acquisition max means uncertainty and predicted objective are high.\n",
    "### Sample the next trial according to the acquisition function\n",
    "### Trade off exploration and exploitation\n",
    "## Limitation of BO:\n",
    "### In the initial stages, similar to random search\n",
    "### Optimization process is sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successive Having (SH)\n",
    "### Save the budget for most promising config\n",
    "### Randomly pick n configurations to train m epochs\n",
    "### Repeat until one configuration left:\n",
    "    keep the best n/2 configuration to train another m epochs\n",
    "    keep the best n/4 configuration to train another 2m epochs\n",
    "### select n and m based on training budget and # epoch needed for a full training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperband (more suitable for deep neural network, because we can select a sample from the data to run it)\n",
    "### In successive Halving\n",
    "    n : exploration\n",
    "    m : exploitation\n",
    "### Hyperband runs multiple Successive Halving, each time decreases n and increases m\n",
    "    more exploration first, then do more exploit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAS algorithms - Neural Architecture Search\n",
    "## NAS automates the design of neural network\n",
    "### how to specify the search space of NN\n",
    "### how to explore the search space\n",
    "### performance estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The one-shot approach\n",
    "### Combines the learning of architecture and model params\n",
    "### Construct and train a single model presents a wide variety of architectures\n",
    "### Evaluate candidate architectures\n",
    "    only care about the candidate ranking\n",
    "    use a proxy metric: the accuracy after a few epochs\n",
    "### re-train the most promising candidate from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "## Standardizing data makes the loss smother for linear methods\n",
    "### smooth: ||df(x) - df(y)||^2 <= beta*||x-y||^2\n",
    "### a smaller beta allows a larger learning rate\n",
    "### does not help deep NN\n",
    "## Batch Normalization (BN) standards inputs for internal layer\n",
    "### improves the smoothness to make training easier\n",
    "### (still controversial why BN works)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape input X into 2D (no change for 2D input X -> R(n*p))\n",
    "    x -> R(n*c*w*h) -> x' -> R(nwh*c) (batch n, channel c, width w, height h)\n",
    "### Normalize by standardization each column xj', j = 1,...,n\n",
    "    xj'(hat) <- (xj' - mean(xj')) / std(xj')\n",
    "### Recovery Y' with yj' = gammaj * xj(hat) + betaj as the j-th column, gammaj, betaj params\n",
    "### Output Y by reshaping Y' to the same shape as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code:\n",
    "\n",
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    if not torch.is_grad_enabled(): # in prediction mode\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:  # nlp input\n",
    "            # get the mean for the dim 0\n",
    "            mean = X.mean(dim=0)  \n",
    "            var = ((X - mean)**2).mean(dim=0)\n",
    "        else:\n",
    "            # (1, c, 1, 1), get the mean for the dim (0, 2, 3), the dim 1 are the same as before\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)  # convolution layer input \n",
    "            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean  # moving smooth average\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var  # # moving smooth var\n",
    "    Y = gamma * X_hat + beta\n",
    "    return Y, moving_mean, moving_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Normalization\n",
    "## if apply to RNN, BN needs maintain separated moving statistics for each time step\n",
    "### problematic for very long sequences during inference\n",
    "## Layer normalization reshapes input X -> R(n*p) -> X' -> R(p*n)\n",
    "    X -> R(n*c*w*h) -> X' -> R(cwh*n), rest is same with BN\n",
    "### Normalizing within each example, up to current time step\n",
    "### Consistent between training and inference\n",
    "### Popularized by Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Normalizations\n",
    "## Modify \"reshape\", e.g.\n",
    "### InstanceNorm: n*c*w*h -> wh*cn\n",
    "### GroupNorm: n*c*w*h -> swh*gn with c = sg\n",
    "### CrossNorm: swap mean/ std between a pair of features\n",
    "## Modify \"normalize\": e.g. whitening\n",
    "## Modify \"recovery\": e.g. replace gamma, beta with a dense layer\n",
    "## Apply to weights or gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "## Normalizing inputs of internal layers makes deep NNs easier to train\n",
    "## A normalization layer performs three steps: reshape input, normalize data, recovery with learnable params\n",
    "### Notable examples include Batch Norm for CNNs, Layer Norm for Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "## Motivation \n",
    "### Exploit a model trained on one task for a related task\n",
    "### Popular in deep learning as DNNs are data hungry and training cost is high\n",
    "## Approaches\n",
    "### Feature extraction (e.g. Word2Vec, ResNet-50 feature, I3D feature)\n",
    "### Train a model on a related task and reuse it\n",
    "### Fine-tuning from a pretrained model (focus of this leacture)\n",
    "## Related to \n",
    "### Semi-supervised learning\n",
    "### In the extreme, zero-shot/ few-shot learning\n",
    "### Multi-task learning, where some labeled data is available for each "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Models\n",
    "## Partition a neural network into:\n",
    "### A feature extractor (encoder) maps raw pixels into linearly separable features\n",
    "### A linear classifier (decoder) makes decisions\n",
    "## Pre-trained model\n",
    "### a neural network trained on a large-scale and general enough dataset \n",
    "### The feature extractor may generalize well to\n",
    "    other datasets (e.g. medical/ satellite images)\n",
    "    other tasks (e.g. object detection, segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning techniques\n",
    "## initialize the new model:\n",
    "### initialize the feature extractor with the feature extractor params of a pre-trained model\n",
    "### randomly initialize the output layer\n",
    "### start the params optimization near a local minimal\n",
    "## Train with a small learning rate with just a few epochs\n",
    "### regularize the search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze Bottom Layers\n",
    "## Neural Networks learn hierarchical features\n",
    "### Low-level features are universal, generalize well, e.g. curves/edges/blobs\n",
    "### high-level features are more task and dataset specific, e.g. classfication labels\n",
    "## freeze bottom layers during fine-tuning train the top layers from scratch\n",
    "### keep Low-level universal features intact\n",
    "### focus on learning task specific features\n",
    "### a strong regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where to find pre-trained models\n",
    "## tensorflow hub: https://tfhub.dev/\n",
    "### tensorflow models submitted by users\n",
    "## TIMM: https://github.com/rwightman/pytorch-image-models\n",
    "### pytorch models collected by Ross Wightman\n",
    "\n",
    "import timm\n",
    "from torch import nn\n",
    "\n",
    "model = timm.create_model('resnet18', pretrained=True)\n",
    "# fc -> final layer -> fully connect layer\n",
    "# n_classes is the classes for your task\n",
    "mode.fc = nn.Linear(model.fc.in_features, n_classes)\n",
    "# train model as a normal training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where to find pre-trained nlp models\n",
    "## huggingface: a collection of pre-trained transformers models on both pytorch and tensorflow\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# padding here defines how long the sentence we want for our task\n",
    "inputs = tokenizer(sentences, padding=\"max_length\", truncated=True)\n",
    "# num_labels means we want to do a classification task with 2 classes\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "# train model on inputs as a normal training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
